# Logistic Regression Project - E-commerce Customer Analysis
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) 
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white) 
![Scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)

## Project Description

This repository contains a data analysis project that uses a **logistic regression** model to predict the purchasing behavior of customers at an e-commerce store. The main objective is to determine the probability that a customer will make a purchase (`Purchased = 1`) or will not make a purchase (`Purchased = 0`) based on variables such as their age and the price of the product.

## Repository Contents

* `logistic_regression.ipynb`: The Jupyter notebook containing all the project code, from data loading and cleaning to model training and prediction.
* `ecommerce_customer.csv`: The customer dataset used for analysis and model building.

* ## Technologies Used

* **Python:** Main programming language.
* **Pandas:** For data manipulation and analysis.
* **scikit-learn:** For implementing the logistic regression model.
* **Jupyter Notebook:** The development environment for executing the code.

## Data Source

The `ecommerce_customer.csv` dataset was obtained from **Kaggle**. You can find more information about the original source and license at the following link:

[Name of the Dataset on Kaggle](https://www.kaggle.com/URL_AQUI)

**Note:** Please replace the text `URL_HERE` in the link above with the actual URL of the dataset page on Kaggle.

## How to Use the Project

1.  Make sure you have the necessary libraries installed: Pandas and Scikit-learn. You can install them using pip:
    `pip install pandas scikit-learn`
2.  Open the Jupyter notebook in your preferred environment.
3.  Run the notebook cells one by one to see the analysis flow, from data loading to final prediction.
